{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cd99af",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f15646b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 19:48:19.614141: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-24 19:48:23.302301: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Dataloader'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_82065/630560701.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mDataloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_image_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Dataloader'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from Dataloader import load_image_dataset\n",
    "import random\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abfc8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load image datasets using your Dataloader module\n",
    "train_ds, valid_ds = load_image_dataset(\"/home/randolpwanjiru/DSP4380/Computer Vision/archive (17)/pizza_not_pizza\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435cc786",
   "metadata": {},
   "source": [
    "* using MobileNetV2 from keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db2465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mobilenet_model(input_shape, num_classes):\n",
    "    # Load the MobileNetV2 model without the top (fully connected) layers\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "    # Freeze the convolutional layers in the base model\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Add custom layers on top of the base model\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    output = Dense(num_classes, activation='sigmoid')(x)  # Assuming binary classification\n",
    "\n",
    "    # Create the final model\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d9a406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input shape and number of classes\n",
    "input_shape = (224, 224, 3)  # Assuming images of size 224x224 and 3 channels (RGB)\n",
    "num_classes = 1  # Assuming binary classification\n",
    "\n",
    "# Build the model\n",
    "model = build_mobilenet_model(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "lr = 0.0001\n",
    "model.compile(optimizer=Adam(learning_rate=lr),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model (assuming you have train_generator and validation_generator)\n",
    "history = model.fit(train_ds, epochs=10, validation_data=valid_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c74a4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(history.history[\"loss\"])),history.history[\"loss\"],label=\"Training Loss\")\n",
    "plt.plot(range(len(history.history[\"val_loss\"])),history.history[\"val_loss\"],label=\"Validation Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5da73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(history.history[\"accuracy\"])),history.history[\"accuracy\"],label=\"Training Accuracy\")\n",
    "plt.plot(range(len(history.history[\"val_accuracy\"])),history.history[\"val_accuracy\"],label=\"Validation Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c009a03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"TrainBaseModel.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
