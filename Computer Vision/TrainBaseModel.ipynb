{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f15646b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e31a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87b90618",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Dataloader'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_79570/1296277252.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mDataloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_image_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Dataloader'"
     ]
    }
   ],
   "source": [
    "from Dataloader import load_image_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abfc8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load image datasets using your Dataloader module\n",
    "train_ds, valid_ds = load_image_dataset(\"/home/randolpwanjiru/DSP4380/Computer Vision/archive (17)/pizza_not_pizza\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435cc786",
   "metadata": {},
   "source": [
    "* using MobileNetV2 from keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db2465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mobilenet_model(input_shape, num_classes):\n",
    "    # Load the MobileNetV2 model without the top (fully connected) layers\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "    # Freeze the convolutional layers in the base model\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Add custom layers on top of the base model\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    output = Dense(num_classes, activation='sigmoid')(x)  # Assuming binary classification\n",
    "\n",
    "    # Create the final model\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d9a406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input shape and number of classes\n",
    "input_shape = (224, 224, 3)  # Assuming images of size 224x224 and 3 channels (RGB)\n",
    "num_classes = 1  # Assuming binary classification\n",
    "\n",
    "# Build the model\n",
    "model = build_mobilenet_model(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "lr = 0.0001\n",
    "model.compile(optimizer=Adam(learning_rate=lr),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model (assuming you have train_generator and validation_generator)\n",
    "history = model.fit(train_ds, epochs=10, validation_data=valid_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c74a4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(history.history[\"loss\"])),history.history[\"loss\"],label=\"Training Loss\")\n",
    "plt.plot(range(len(history.history[\"val_loss\"])),history.history[\"val_loss\"],label=\"Validation Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5da73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(history.history[\"accuracy\"])),history.history[\"accuracy\"],label=\"Training Accuracy\")\n",
    "plt.plot(range(len(history.history[\"val_accuracy\"])),history.history[\"val_accuracy\"],label=\"Validation Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c009a03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"TrainBaseModel.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da004152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.saved_model.save(model, 'TrainBaseModel')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
